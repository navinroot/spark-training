import org.apache.spark._
import org.apache.spark.streaming._
import java.text.SimpleDateFormat

val ssc= new StreamingContext(sc, Seconds(5))

val fileStream = ssc.textFileStream("/home/spark/ch06input")

import java.sql.Timestamp

case class Order(time:java.sql.Timestamp, orderId:Long, clientId:Long, symbol: String, amount: Int, price: Double , buy:Boolean)

val orders= fileStream.flatMap(line =>{
      val dateFormat= new SimpleDateFormat("yyyy-MM-dd hh:mm:ss")
      val s=line.split(",")
      try{
      assert(s(6)=="B" ||  s(6)=="S")
      List(Order(new Timestamp(dateFormat.parse(s(0)).getTime()),
      s(1).toLong,s(2).toLong,s(3),s(4).toInt,s(5).toDouble,s(6)=="B"))
      }
      catch{
      case e : Throwable => println("Wrong line format ("+e+"): "+line)
      List()
      }
      }
      )

val numPerType =orders.map(o=> (o.buy,1L)).reduceByKey(_+_)

val amountPerClient = orders.map(o=> (o.clientId, o.amount*o.price))

val amountState = amountPerClient.updateStateByKey((vals,totalOpt:Option[Double])=>{
      totalOpt match{
      case Some(total) => Some(vals.sum +total)
      case None => Some(vals.sum)
      }
      })
	  
val top5Clients = amountState.transform(_.sortBy(_._2, false).map(_._1).
      zipWithIndex.filter(x=> x._2 <5))
	  
val buySellList= numPerType.map(t =>
      if(t._1) ("BUYS",List(t._2.toString))
      else ("SELLS",List(t._2.toString)))

val top5clList = top5Clients.repartition(1).
      map(x=>x._1.toString).glom().map(arr => ("TOP5CLIENTS", arr.toList))

val finalStream=buySellList.union(top5clList)

finalStream.repartition(1).saveAsTextFiles("/home/spark/ch06output/output","txt")

sc.setCheckpointDir("/home/spark/checkpoint")

ssc.start()

ssc.stop(false)

	

// * use mapWithState

val updateAmountState = (clientId:Long, amount: Option[Double],
      state:State[Double]) => {
      var total = amount.getOrElse(0.toDouble)
      if(state.exists())
        total += state.get()
      state.update(total)
      Some((clientId, total))
      }
	
val amountState = amountPerClient.mapWithState(StateSpec.
      function(updateAmountState)).stateSnapshots()

	 
// * use window in streaming

val stockPerWindow = orders.
      map(x=> (x.symbol, x.amount)).window(Minutes(60)).
      reduceByKey(_+_)

val topStocks= stockPerWindow.transform(_.sortBy(_._2, false).map(_._1).
      zipWithIndex.filter(x=> x._2 <5)).repartition(1).
      map(x=> x._1.toString).glom().
      map(arr => ("TOP5STOCKS", arr.toList))
	 
val finalStream= buySellList.union(top5clList).union(topStocks)

finalStream.repartition(1).saveAsTextFiles("/home/spark/ch06output/output","txt")

ssc.start()

ssc.stop(false)


// * spark streaming using kafka



